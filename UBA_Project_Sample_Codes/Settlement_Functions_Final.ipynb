{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3338eab7",
   "metadata": {},
   "source": [
    "### Importing the relavant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a14f13ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUNCTION CALLED: read_report_file\n",
      "==READING IN THE FILE ./033_REPORTS_05032023/30/2PM/033_INCOMING_COMMISSIONS_SUMMARY_30112023_PM.CSV\n",
      "Format: CSV\n",
      "STEP 1: Checking if the file has a header or not\n",
      "STEP 2: File has no header\n",
      "==END OF FUNCTION: READ REPORT FILE==\n",
      "\n",
      "FUNCTION EXECUTION ENDED: read_report_file\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import PyPDF2\n",
    "from datetime import datetime\n",
    "from io import StringIO\n",
    "\n",
    "\n",
    "%run \"./excel_functions.ipynb\"\n",
    "\n",
    "current_time = datetime.now().strftime(format = \"%H:%M:%S\")\n",
    "\n",
    "#main_folder_path = \"./033_REPORTS_05032023/\"\n",
    "babcock_only_sum = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3305bfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the current date\n",
    "# current_date = datetime.now()\n",
    "\n",
    "# # Format the date\n",
    "# formatted_date = current_date.strftime(\"%d %b %Y\")\n",
    "\n",
    "# # Get current hour\n",
    "# current_hour = datetime.now().hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa3813a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_folder_hour(main_folder_path):\n",
    "    \n",
    "    folder_hour = [path_component for path_component in main_folder_path.split(\"/\") if path_component !=\"\"]\n",
    "    \n",
    "    try:\n",
    "        folder_hour = folder_hour[-1] #The folder hour is the last component of the path\n",
    "    \n",
    "    except IndexError as e:\n",
    "        print(f\"Folder hour value: {folder_hour}\")\n",
    "        print(f\"Python error: {e}\")\n",
    "        return \"\"\n",
    "        \n",
    "    return folder_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8abdf4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42dea746",
   "metadata": {},
   "source": [
    "### Creating a list of keywords for every report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "274d56a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_reports = [\"incoming_commissions_summary\",\n",
    "                  \"incoming_commissions_details\",\n",
    "                  \"incoming_cpay_details\",\n",
    "                  \"incoming_reversal_details\",\n",
    "                  \"incoming_transfers_details\",\n",
    "                  \"incoming_payments_summary\",\n",
    "                  \"outgoing_cardloads_details\",\n",
    "                  \"outgoing_commissions_summary\",\n",
    "                  \"outgoing_reversal_details\",\n",
    "                  \"outgoing_cpay_details\",\n",
    "                  \"outgoing_comm_summary_details\",\n",
    "                  \"samebank_commissions_summary\",\n",
    "                  \"outgoing_payments_detail\",\n",
    "                   \"net_settlement_position\"\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e469af06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49422ab2",
   "metadata": {},
   "source": [
    "### A function for renaming files:\n",
    "\n",
    "**This is used for removing errors regarding the spelling of \"commission\" in the filenames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "664685a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_name_decorator\n",
    "def _rename_files(directory_path):\n",
    "    # List all files in the directory\n",
    "    files = os.listdir(directory_path)\n",
    "\n",
    "    # Iterate through each file\n",
    "    for filename in files:\n",
    "        # Check if the file contains the misspelled word\n",
    "        if \"commssion\" in filename.lower():\n",
    "            # Generate the new filename by replacing the misspelled word\n",
    "            new_filename = filename.replace(\"COMMSSION\", \"COMMISSION\")\n",
    "\n",
    "            # Construct the full paths\n",
    "            old_path = os.path.join(directory_path, filename)\n",
    "            new_path = os.path.join(directory_path, new_filename)\n",
    "\n",
    "            # Rename the file\n",
    "            os.rename(old_path, new_path)\n",
    "\n",
    "            print(f\"Renamed: {filename} to {new_filename}\")\n",
    "    #print(\"==END OF FUNCTION: RENAME FILES==\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce949e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0fa789f",
   "metadata": {},
   "source": [
    "### A function for generating folder names 7AM, 11AM, 2PM & 5PM:\n",
    "\n",
    "This function helps other parts of the code decide which folder to access for transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f78ba69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_name_decorator\n",
    "def _convert_hour_to_am_pm(hour, for_folder = False):\n",
    "    \n",
    "    try:\n",
    "        hour = int(hour)\n",
    "        \n",
    "    except ValueError as e:\n",
    "        print(f\"The argument inputted is not a number.\\Python error: {e}\")\n",
    "        warnings.warn(f\"Returning the original input without any transformations\")\n",
    "        return hour\n",
    "    \n",
    "    if hour < 7:\n",
    "        if for_folder:\n",
    "            return \"7AM/\"\n",
    "        \n",
    "        else:\n",
    "            return \"7AM\"\n",
    "        \n",
    "        \n",
    "    elif hour > 7 and hour < 11:\n",
    "        if for_folder:\n",
    "            return \"11AM/\"\n",
    "        else:\n",
    "            return \"11AM\"\n",
    "    \n",
    "    elif hour > 11 and hour < 14:\n",
    "        if for_folder:\n",
    "            return \"2PM/\"\n",
    "        else:\n",
    "            return \"2PM\"\n",
    "        \n",
    "    else:\n",
    "        if for_folder:\n",
    "            return \"5PM/\"\n",
    "        else:\n",
    "            return \"5PM\"\n",
    "    \n",
    "    #print(\"==END OF FUNCTION: CONVERT HOUR TO AM PM==\\n\")\n",
    "# folder_path = main_folder_path + _convert_hour_to_am_pm(current_hour, for_folder= True)\n",
    "# folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab60d3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27ac5fb8",
   "metadata": {},
   "source": [
    "### A function that generates a list of Report files:\n",
    "\n",
    "This function reaches into the required folder: 7AM, 11AM, 2PM, and 5PM and generates the list of files available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4781be71",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_name_decorator\n",
    "def list_of_files_generator(main_folder_path):\n",
    "    \n",
    "    folder_hour = _get_folder_hour(main_folder_path)\n",
    "    \n",
    "    print(f\"\\n==GENERATING THE LIST OF FILES FOR {folder_hour}\")\n",
    "    print(f\"The current time: {current_time}\")\n",
    "    \n",
    "    print(f\"STEP 1: Listing all the files available in the {folder_hour} folder\")\n",
    "    \n",
    "    try:\n",
    "        list_of_files = os.listdir(main_folder_path)\n",
    "    \n",
    "    except FileNotFoundError as e:\n",
    "        warnings.warn(f\"Folder {main_folder_path} could not be found\")\n",
    "        print(\"Returning an empty string as the list of files\")\n",
    "        return \"\"\n",
    "    \n",
    "    for file in list_of_files:\n",
    "        print(file)\n",
    "        \n",
    "    \n",
    "    if len(list_of_files) == 0:\n",
    "        warnings.warn(f\"There are NO files in {folder_hour} folder\")\n",
    "        print(\"Returning an empty string as the list of files\")\n",
    "        return \"\"\n",
    "    \n",
    "    else:\n",
    "        #print(\"==END OF FUNCTION: LIST OF FILES GENERATOR==\\n\")\n",
    "        return list_of_files\n",
    "    \n",
    "# list_of_files = list_of_files_generator(main_folder_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407fa273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34f91875",
   "metadata": {},
   "source": [
    "### A function to get Net Settlement PDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef1a848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_name_decorator\n",
    "def _get_net_settlement_path(keyword, list_of_files):\n",
    "    print(\"\\n==GETTING THE PATH FOR NET SETTLEMENT PDF FILE\")\n",
    "    \n",
    "    print(f\"STEP 1: Looping through the files in the directory (List of files) in the {_convert_hour_to_am_pm(current_hour)} directory\")\n",
    "    for filename in list_of_files:\n",
    "        if keyword in filename.lower() and filename.lower().endswith(\".pdf\"):\n",
    "            #print(\"==END OF FUNCTION: GET NET SETTLEMENT PATH==\\n\")\n",
    "            return filename\n",
    "          \n",
    "    #print(\"==END OF FUNCTION: GET NET SETTLEMENT PATH==\\n\")\n",
    "    return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb7b923",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c42aeb50",
   "metadata": {},
   "source": [
    "### A function to generate Narration:\n",
    "\n",
    "This function is used to generate the narration for some other functions so that they can fill up their output dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fc866ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_name_decorator\n",
    "def _get_incoming_commissions_narration(keyword, main_folder_path):\n",
    "    print(\"\\n==CREATING NARRATION FOR INCOMING COMMISSIONS SUMMARY==\")\n",
    "    narration = \"\"\n",
    "    \n",
    "    print(\"STEP 1: Getting the file path for the settlement PDF file\")\n",
    "    required_filename = _get_net_settlement_path(keyword, list_of_files)\n",
    "    \n",
    "    \n",
    "    if required_filename == \"\":\n",
    "        warnings.warn(\"Could not find the Settlement PDF file\")\n",
    "        return \"\"\n",
    "    \n",
    "    pdf_text = read_pdf(main_folder_path+ required_filename)\n",
    "\n",
    "    batch_id = pdf_text.split(\"Batch Id: \")[1].split()[0]\n",
    "\n",
    "    print(\"STEP 2: Recording the Narration\")\n",
    "    narration = batch_id + \"/\" + formatted_date + \"/IN COMM\"\n",
    "    \n",
    "    if batch_id == \"\":\n",
    "        warnings.warn(\"No Batch ID for narration found\")\n",
    "        #print(\"==END OF FUNCTION: GET INCOMING COMMISSIONS NARRATION==\\n\")\n",
    "        return narration\n",
    "    \n",
    "    else:\n",
    "        #print(\"==END OF FUNCTION: GET INCOMING COMMISSIONS NARRATION==\\n\")\n",
    "        return narration\n",
    "    \n",
    "# _get_incoming_commissions_narration(\"net_settlement_position\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbd8c64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9b99a87",
   "metadata": {},
   "source": [
    "### A function for generating INCOMING_COMMISSION_DETAILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13d40ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_name_decorator\n",
    "def incoming_commission_details(filepath):\n",
    "    \n",
    "    print(\"\\n==STEPS FOR INCOMING COMMISSION DETAILS==\")\n",
    "    print(\"STEP 1: Reading in the file\")\n",
    "    df, has_no_header = read_report_file(filepath)\n",
    "    \n",
    "    if has_no_header == True:\n",
    "        print(\"STEP 2: Adding column names to the data\")\n",
    "        df = add_letter_columns_to_df(df)\n",
    "    \n",
    "    elif has_no_header == \"NA\":\n",
    "        warnings.warn(\"File was not found!\")\n",
    "        return \"\"\n",
    "    \n",
    "    print(\"STEP 3: Sorting values by column 'I'\")\n",
    "    incoming_commissions_df = df.sort_values(\"I\")\n",
    "    \n",
    "    print(\"STEP 4: Selecting only values with 'BABCOCK' from column I\")\n",
    "    babcock_mask = incoming_commissions_df[\"I\"].str.contains(\"BABCOCK\")\n",
    "    babcock_df = incoming_commissions_df.loc[babcock_mask, :]\n",
    "\n",
    "    print(\"STEP 5: Moving column 'H', to column 'A'\")\n",
    "    babcock_df = excel_move_column(babcock_df, \"H\", \"A\")\n",
    "    \n",
    "    print(\"STEP 6: Moving column 'F' to column 'B'\")\n",
    "    babcock_df = excel_move_column(babcock_df, \"F\", \"B\")\n",
    "    \n",
    "    print(\"STEP 7: Moving column 'F' to 'C'\")\n",
    "    babcock_df = excel_move_column(babcock_df, \"F\", \"C\")\n",
    "    \n",
    "    print(\"STEP 8: Inserting 2 column spaces between columns D and E\")\n",
    "    babcock_df = generate_inner_columns(babcock_df, 2, \"D\")\n",
    "    \n",
    "    print(\"STEP 9: Getting the last 7 characters from column C and inserting in column D\")\n",
    "    babcock_df.loc[:, \"D\"] = babcock_df[\"C\"].str[-7:]\n",
    "    \n",
    "    print(\"STEP 10: Concatenating columns D and C\")\n",
    "    babcock_df[\"E\"] = babcock_df[\"D\"] + babcock_df[\"C\"]\n",
    "    \n",
    "    print(\"STEP 11: Copy the values of column E to column C\")\n",
    "    babcock_df.loc[:, \"C\"] = babcock_df[\"E\"].copy()\n",
    "    \n",
    "    print(\"STEP 12: Remove the 'PAYMENT' word from column C\")\n",
    "    babcock_df[\"C\"] = babcock_df[\"C\"].str.replace(\"PAYMENT\", \"\")\n",
    "    \n",
    "    print(\"STEP 13: Selecting only columns 'A', 'B', and 'C'\")\n",
    "    babcock_incoming_commissions_settlement = babcock_df.loc[:, [\"A\", \"B\", \"C\"]]\n",
    "    \n",
    "    print(\"STEP 14: Renaming the columns to: ACCOUNT, AMOUNT, and NARRATION\")\n",
    "    babcock_incoming_commissions_settlement.rename(columns= {\"A\": \"ACCOUNT\", \"B\": \"AMOUNT\", \n",
    "                                                             \"C\": \"NARRATION\"}, inplace = True)\n",
    "    \n",
    "    global babcock_only_sum\n",
    "    \n",
    "    babcock_only_sum = babcock_incoming_commissions_settlement[\"AMOUNT\"].astype(float).sum()\n",
    "    \n",
    "    #print(\"==END OF FUNCTION: INCOMING COMMISSIONS DETAILS==\\n\")\n",
    "    return babcock_incoming_commissions_settlement\n",
    "\n",
    "# babcock_incoming_commissions_details_df = incoming_commission_details(\"033_REPORTS_05032023/033_INCOMING_COMMISSIONS_DETAILS_05032023_AM.CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f93728a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e71dc52c",
   "metadata": {},
   "source": [
    "### A function for generating INCOMING_COMMISSIONS_SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66f88401",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_name_decorator\n",
    "def incoming_commissions_summary(filepath):\n",
    "    \n",
    "    print(\"\\n==STEPS FOR INCOMING COMMISSIONS SUMMARY==\")\n",
    "    print(\"STEP 1: Reading in the file\")\n",
    "    df, has_no_header = read_report_file(filepath)\n",
    "    \n",
    "    if has_no_header:\n",
    "        print(\"STEP 2: Adding column names to the data\")\n",
    "        df = add_letter_columns_to_df(df)\n",
    "    \n",
    "    elif has_no_header == \"NA\":\n",
    "        warnings.warn(\"File was not found!\")\n",
    "        return \"\"\n",
    "    \n",
    "    print(\"STEP 3: Comparing Babcock settlement sums from INCOMING COMMISSIONS SUMMARY and result from data manipulation\")\n",
    "    babcock_mask = df[\"C\"].str.lower().str.contains(\"babcock\")\n",
    "    babcock_summary_amount = df.loc[babcock_mask, \"D\"].sum()\n",
    "    print(f\"babcock summary amount: {babcock_summary_amount}\")\n",
    "    print(f\"babcock only sum: {babcock_only_sum}\")\n",
    "    #confirmation_mask = babcock_incoming_commissions_details_df[\"AMOUNT\"].sum() == df[\"D\"]\n",
    "\n",
    "    if babcock_summary_amount == babcock_only_sum:\n",
    "        print(\"Successfully confirmed Babcock settlement value\")\n",
    "    \n",
    "    else:\n",
    "        warnings.warn(\"Babcock settlement value not confirmed!\")\n",
    "        \n",
    "    \n",
    "    print(\"STEP 4: Considering all records in the summary except Babcock...\")\n",
    "    except_babcock_mask = ~(df[\"C\"].str.lower().str.contains(\"babcock\"))\n",
    "    incoming_commissions_summary_df = df.loc[except_babcock_mask, :]\n",
    "    \n",
    "    print(\"STEP 5: Reading the Batch ID from the NET SETTLEMENT POSITION\")\n",
    "    narration = _get_incoming_commissions_narration(\"net_settlement_position\", main_folder_path)\n",
    "    \n",
    "    print(\"STEP 7: Selecting only columns B and D\")\n",
    "    incoming_commissions_settlement = incoming_commissions_summary_df.loc[:, [\"B\", \"D\"]]\n",
    "    \n",
    "    print(\"STEP 8: Rename the columns to ACCOUNT AND AMOUNT\")\n",
    "    incoming_commissions_settlement.columns = [\"ACCOUNT\", \"AMOUNT\"]\n",
    "    \n",
    "    print(\"STEP 9: Including the NARRATION column to the output dataframe\")\n",
    "    if narration == \"\":\n",
    "        warnings.warn(\"NARRATION was not extracted from NET SETTLEMENT POSITION PDF FILE. This may be because the file is not in PATH\")\n",
    "    incoming_commissions_settlement.loc[:, \"NARRATION\"] = narration\n",
    "    \n",
    "    #print(\"==END OF FUNCTION: INCOMING COMMISSIONS SUMMARY==\\n\")\n",
    "    return incoming_commissions_settlement\n",
    "\n",
    "# filepath = \"033_REPORTS_05032023/033_INCOMING_COMMISSIONS_SUMMARY_05032023_AM.CSV\"\n",
    "# net_settlement_position_pdf_file_path = \"./033_REPORTS_05032023/033_NET_SETTLEMENT_POSITION_05032023_AM.PDF\"\n",
    "# incoming_commissions_summary_df = incoming_commissions_summary(filepath)\n",
    "# incoming_commissions_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ae6011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9737c3dd",
   "metadata": {},
   "source": [
    "### A function for generating INCOMING_TRANSFER_DETAILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8184732c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_name_decorator\n",
    "def incoming_transfer_details(filepath):\n",
    "    \n",
    "    print(\"\\n==STEPS FOR INCOMING TRANSFER DETAILS==\")\n",
    "    \n",
    "    print(\"STEP 1: Reading in the file\")\n",
    "    incoming_transfer_df, has_no_header = read_report_file(filepath)\n",
    "    \n",
    "    if has_no_header:\n",
    "        print(\"STEP 2: Adding column names to the data\")\n",
    "        incoming_transfer_df = add_letter_columns_to_df(incoming_transfer_df)\n",
    "    \n",
    "    elif has_no_header == \"NA\":\n",
    "        warnings.warn(\"File was not found!\")\n",
    "        return \"\"\n",
    "    \n",
    "    print(\"STEP 3: Summing up the values of column H\")\n",
    "    auto_sum = incoming_transfer_df[\"H\"].fillna(0).astype(float).sum()\n",
    "    \n",
    "    print(\"STEP 4: Extracting the Account ID from column G\")\n",
    "    account_num = incoming_transfer_df[\"G\"].unique()[0]\n",
    "    \n",
    "    print(\"STEP 5: Create a dictionary for the Account extracted and Amount calculated\")\n",
    "    auto_sum_acct_num_dict = {\n",
    "    \n",
    "   \"ACCOUNT\": [account_num],\n",
    "    \"AMOUNT\": [auto_sum]\n",
    "    }\n",
    "    \n",
    "    print(\"STEP 6: Convert the dictionary into a DataFrame\")\n",
    "    income_transfer_settlement_df = pd.DataFrame(auto_sum_acct_num_dict)\n",
    "\n",
    "    print(\"STEP 7: Including the NARRATION in the DataFrame\")\n",
    "    income_transfer_settlement_df [\"NARRATION\"] = f\"Incoming Transfers {formatted_date} S1\"\n",
    "    \n",
    "    #print(\"==END OF FUNCTION: INCOMING TRANSFER DETAILS==\\n\")\n",
    "    return income_transfer_settlement_df\n",
    "\n",
    "# filepath = \"033_REPORTS_05032023/033_INCOMING_TRANSFERS_DETAILS_06032023_AM.CSV\"\n",
    "# incoming_transfer_details_df = incoming_transfer_details(filepath)\n",
    "# incoming_transfer_details_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc34d2a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f684219b",
   "metadata": {},
   "source": [
    "### A function for generating OUTGOING_COMMISSIONS_SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b75bd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_name_decorator\n",
    "def outgoing_commissions_summary(filepath):\n",
    "    \n",
    "    print(\"\\n==STEPS FOR OUTGOING COMMISSIONs SUMMARY==\")\n",
    "\n",
    "    print(\"STEP 1: Reading in the file\")\n",
    "    outgoing_summary_df, has_no_header = read_report_file(filepath)\n",
    "    \n",
    "    if has_no_header:\n",
    "        print(\"STEP 2: Adding column names to the data\")\n",
    "        outgoing_summary_df = add_letter_columns_to_df(outgoing_summary_df)\n",
    "    \n",
    "    elif has_no_header == \"NA\":\n",
    "        warnings.warn(\"File was not found!\")\n",
    "        return \"\"\n",
    "    \n",
    "    print(\"STEP 3: Create a dictionary mapping column headers to their respective values\")\n",
    "    outgoing_summary_dict = outgoing_summary_df.to_dict(\"list\")\n",
    "\n",
    "    print(\"STEP 4: Selecting just column headers B and D and their values\")\n",
    "    cols_to_retrieve = [\"B\", \"D\"]\n",
    "    selected_summary_dict = {key: outgoing_summary_dict[key] for key in cols_to_retrieve if key in outgoing_summary_dict}\n",
    "    \n",
    "    print(\"STEP 5: Including the NARRATION in the dictionary\")\n",
    "    selected_summary_dict[\"NARRATION\"] = [f\"OUTGOING COMM {formatted_date} S1\"] * len(outgoing_summary_df)\n",
    "    \n",
    "    print(\"STEP 6: Creating a DataFrame from the dictionary\")\n",
    "    outgoing_commission_summary_df = pd.DataFrame(selected_summary_dict)\n",
    "    \n",
    "    print(\"STEP 7: Negating the values of column D because it is an 'Outgoing' value\")\n",
    "    outgoing_commission_summary_df.loc[:, \"D\"] = outgoing_commission_summary_df[\"D\"].apply(abs) * -1\n",
    "\n",
    "    print(\"STEP 8: Renaming the columns of the final dataframe\")\n",
    "    outgoing_commission_summary_df.rename(columns = {\"B\": \"ACCOUNT\", \"D\": \"AMOUNT\"}, inplace = True)\n",
    "    \n",
    "    #print(\"==END OF FUNCTION: OUTGOING COMMISSION SUMMARY==\\n\")\n",
    "    return outgoing_commission_summary_df\n",
    "\n",
    "\n",
    "# filepath = \"033_REPORTS_05032023/033_OUTGOING_COMMSSIONS_SUMMARY_05032023_AM.CSV\"\n",
    "# outgoing_commission_summary_df = outgoing_commissions_summary(filepath)\n",
    "# outgoing_commission_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443c2c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "948c15b3",
   "metadata": {},
   "source": [
    "### A function for generating OUTGOING_PAYMENTS_SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2757f195",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_name_decorator\n",
    "def outgoing_payments_summary(filepath):\n",
    "    \n",
    "    print(\"\\n==STEPS FOR OUTGOING PAYMENTS SUMMARY==\")\n",
    "    \n",
    "    print(\"STEP 1: Reading the file for OUTGOING PAYMENTS SUMMARY...\")\n",
    "    print(\"STEP 1: Reading in the file\")\n",
    "    outgoing_payments_df, has_no_header = read_report_file(filepath)\n",
    "    \n",
    "    if has_no_header:\n",
    "        print(\"STEP 2: Adding column names to the data\")\n",
    "        outgoing_payments_df = add_letter_columns_to_df(outgoing_payments_df)\n",
    "    \n",
    "    elif has_no_header == \"NA\":\n",
    "        warnings.warn(\"File was not found!\")\n",
    "        return \"\"\n",
    "    \n",
    "    print(\"STEP 3: Filling NA in column J and taking the sum of column D values for each category in column J\")\n",
    "    outgoing_payments_df[\"J\"].fillna(method=\"ffill\", inplace = True)\n",
    "    outgoing_payments_settlement_df = outgoing_payments_df.groupby(\"J\").agg({\"D\": \"sum\"}).reset_index()\n",
    "    \n",
    "    print(\"STEP 4: Because this is an outgoing file, the values of aggregated column D is negated\")\n",
    "    outgoing_payments_settlement_df.loc[:, \"D\"] = outgoing_payments_settlement_df[\"D\"].apply(abs) * -1\n",
    "    \n",
    "    print(\"STEP 5: Renaming the columns\")\n",
    "    outgoing_payments_settlement_df.rename(columns = {\"J\": \"ACCOUNT\", \"D\": \"AMOUNT\"}, inplace = True)\n",
    "    \n",
    "    print(\"STEP 6: Including the NARRATION in the DataFrame\")\n",
    "    outgoing_payments_settlement_df[\"NARRATION\"] = f\"Outgoing Payment {formatted_date} S1\"\n",
    "\n",
    "    print(\"STEP 7: In case there is any missing value in ACCOUNT column, fill it with the value specified\")\n",
    "    outgoing_payments_settlement_df[\"ACCOUNT\"].fillna(value = \"NGN09992501102\")\n",
    "    \n",
    "    #print(\"==END OF FUNCTION: OUTGOING PAYMENTS SUMMARY==\\n\")\n",
    "    return outgoing_payments_settlement_df\n",
    "\n",
    "\n",
    "# filepath = \"033_REPORTS_05032023/033_OUTGOING_PAYMENTS_SUMMARY_05032023_AM.CSV\"\n",
    "# outgoing_payments_summary_df = outgoing_payments_summary(filepath)\n",
    "# outgoing_payments_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9815bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fb31172",
   "metadata": {},
   "source": [
    "### A function for generating SAMEBANK_COMMISSIONS_SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac0bb34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_name_decorator\n",
    "def samebank_commissions_summary(filepath):\n",
    "    \n",
    "    print(\"\\n==STEPS FOR SAMEBANK COMMISSIONS SUMMARY==\")\n",
    "    \n",
    "    print(\"STEP 1: Reading the file for SAMEBANK COMMISSIONS SUMMARY...\")\n",
    "    print(\"STEP 1: Reading in the file\")\n",
    "    same_bank_commission_df, has_no_header = read_report_file(filepath)\n",
    "    \n",
    "    if has_no_header:\n",
    "        print(\"STEP 2: Adding column names to the data\")\n",
    "        same_bank_commission_df = add_letter_columns_to_df(same_bank_commission_df)\n",
    "    \n",
    "    elif has_no_header == \"NA\":\n",
    "        warnings.warn(\"File was not found!\")\n",
    "        return \"\"\n",
    "    \n",
    "    print(\"STEP 3: Selecting columns B and F from the SAMEBANK COMMISSIONS DataFrame\")\n",
    "    col_B_F = same_bank_commission_df.loc[:, [\"B\", \"F\"]]\n",
    "    \n",
    "    print(\"STEP 4: Adding the NARRATION for the DataFrame containing columns B and F\")\n",
    "    col_B_F.loc[:, \"NARRATION\"] = f\"23CSA53028163_A/{formatted_date}/SMBK COMM\"\n",
    "    \n",
    "    print(\"STEP 5: Renaming the column headers\")\n",
    "    col_B_F.rename(columns = {\"B\": \"ACCOUNT\", \"F\": \"AMOUNT\"}, inplace = True)\n",
    "\n",
    "    print(\"STEP 6: Repeating the above steps (3-5) for columns E and F\")\n",
    "    col_E_F = same_bank_commission_df.loc[:, [\"E\", \"F\"]]\n",
    "    col_E_F.loc[:, \"NARRATION\"] = f\"23CSA53028163_A/{formatted_date}/SMBK COMM\"\n",
    "    \n",
    "    print(\"STEP 7: Negating the values on column F because column E gives the values to be negated\")\n",
    "    col_E_F.loc[:, \"F\"] = col_E_F[\"F\"].apply(abs) * -1\n",
    "    \n",
    "    print(\"STEP 8: Renaming the column headers\")\n",
    "    col_E_F.rename(columns = {\"E\": \"ACCOUNT\", \"F\": \"AMOUNT\"}, inplace = True)\n",
    "    \n",
    "    print(\"STEP 9: Combining both DataFrames\")\n",
    "    same_bank_commission_settlement = pd.concat([col_B_F, col_E_F])\n",
    "    \n",
    "    #print(\"==END OF FUNCTION: SAMEBANK COMMISSION SUMMARY==\\n\")\n",
    "    return same_bank_commission_settlement\n",
    "\n",
    "# filepath = \"033_REPORTS_05032023/033_SAMEBANK_COMMSSIONS_SUMMARY_05032023_AM.CSV\"\n",
    "# samebank_commissions_summary_df = samebank_commissions_summary(filepath)\n",
    "# samebank_commissions_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f32f832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "767818de",
   "metadata": {},
   "source": [
    "### A function for generating INCOMING_REVERSAL_DETAILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49c93e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_name_decorator\n",
    "def incoming_reversal_details(filepath):\n",
    "    \n",
    "    print(\"==\\nSTEPS FOR INCOMING REVERSAL DETAILS\")\n",
    "    \n",
    "    print(\"STEP 1: Reading in the file INCOMING_REVERSAL_DETAILS...\")\n",
    "    df, has_no_header = read_report_file(filepath)\n",
    "    \n",
    "    if has_no_header:\n",
    "        print(\"STEP 2: Adding column names to the data\")\n",
    "        df = add_letter_columns_to_df(df)\n",
    "    \n",
    "    elif has_no_header == \"NA\":\n",
    "        warnings.warn(\"File was not found!\")\n",
    "        return \"\"\n",
    "    \n",
    "    print(\"STEP 3: Calculating the transaction amount by summing up column D\")\n",
    "    transaction_amount = df[\"D\"].astype(float).sum()\n",
    "    \n",
    "    print(\"STEP 4: Creating a dictionary for the Narration\")\n",
    "    incoming_reversal_dict = {\"ACCOUNT\": [\"NGN09992501102\"],\n",
    "                          \"AMOUNT\": [transaction_amount],\n",
    "                          \"NARRATION\": [f\"Incoming Reversal {formatted_date}\"]\n",
    "                         }\n",
    "    \n",
    "    print(\"STEP 5: Converting the dictionary to a DataFrame\")\n",
    "    incoming_reversal_settlement_df = pd.DataFrame(incoming_reversal_dict)\n",
    "    \n",
    "    #print(\"==END OF FUNCTION: INCOMING REVERSAL DETAILS==\\n\")\n",
    "    \n",
    "    return incoming_reversal_settlement_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88942de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10953c28",
   "metadata": {},
   "source": [
    "### A function for generating OUTGOING_CPAY_COMM_SUMMARY_DETAILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73c00fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_name_decorator\n",
    "def outgoing_cpay_comm_summary_details(filepath):\n",
    "    \n",
    "    print(\"==\\nSTEPS FOR INCOMING REVERSAL DETAILS\")\n",
    "    \n",
    "    print(\"STEP 1: Reading in the file INCOMING_REVERSAL_DETAILS...\")\n",
    "    df, has_no_header = read_report_file(filepath)\n",
    "    \n",
    "    if has_no_header:\n",
    "        print(\"STEP 2: Adding column names to the data\")\n",
    "        df = add_letter_columns_to_df(df)\n",
    "    \n",
    "    elif has_no_header == \"NA\":\n",
    "        warnings.warn(\"File was not found!\")\n",
    "        return \"\"\n",
    "    \n",
    "    print(\"STEP 3: Calculating the transaction amount by summing up column H\")\n",
    "    transaction_amount = df[\"H\"].astype(float).sum()\n",
    "    \n",
    "    print(\"STEP 4: Creating the outgoing cpay comm dictionary\")\n",
    "    outgoing_cpay_comm_dict = {\"ACCOUNT\": [\"1021821845\"],\n",
    "                          \"AMOUNT\": [transaction_amount],\n",
    "                          \"NARRATION\": [f\"Outgoing Cpay COMM {formatted_date}\"]}\n",
    "    \n",
    "    print(\"STEP 5: Negating the AMOUNT because it is outgoing\")\n",
    "    outgoing_cpay_comm_dict[\"AMOUNT\"] = [round(abs(transaction_amount) * -1, 2)]\n",
    "    \n",
    "    print(\"STEP 5: Creating the outgoing cpay comm DataFrame\")\n",
    "    outgoing_cpay_comm_df = pd.DataFrame(outgoing_cpay_comm_dict)\n",
    "    \n",
    "    #print(\"==END OF FUNCTION: OUTGOING CPAY COMM SUMMARY DETAILS==\\n\")\n",
    "    \n",
    "    return outgoing_cpay_comm_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cd0e72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d423398b",
   "metadata": {},
   "source": [
    "### A function for generating OUTGOING_CPAY_DETAILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2dd75a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_name_decorator\n",
    "def outgoing_cpay_details(filepath):\n",
    "    print(\"==\\nSTEPS FOR OUTGOING CPAY DETAILS\")\n",
    "    \n",
    "    print(\"STEP 1: Reading in the file OUTGOING_CPAY_DETAILS...\")\n",
    "    df, has_no_header = read_report_file(filepath)\n",
    "    \n",
    "    if has_no_header:\n",
    "        print(\"STEP 2: Adding column names to the data\")\n",
    "        df = add_letter_columns_to_df(df)\n",
    "    \n",
    "    elif has_no_header == \"NA\":\n",
    "        warnings.warn(\"File was not found!\")\n",
    "        return \"\"\n",
    "    \n",
    "    print(\"STEP 3: Calculating the transaction amount\")\n",
    "    transaction_amount = df[\"TRANS_AMOUNT\"].astype(float).sum()\n",
    "\n",
    "    print(\"STEP 4: Creating the Narration dictionary\")\n",
    "    outgoing_cpay_dict = {\"ACCOUNT\": [\"1021821845\"],\n",
    "                     \"AMOUNT\": [transaction_amount],\n",
    "                     \"NARRATION\": [f\"Outgoing CorporatePay {formatted_date}\"]}\n",
    "    \n",
    "    print(\"STEP 5: Negating the transaction amount because it is outgoing\")\n",
    "    outgoing_cpay_dict[\"AMOUNT\"] = [abs(transaction_amount) * -1]\n",
    "    \n",
    "    print(\"STEP 6: Creating the Final Narration DataFrame\")\n",
    "    outgoing_cpay_settlement_df = pd.DataFrame(outgoing_cpay_dict)\n",
    "    \n",
    "   # print(\"==END OF FUNCTION: OUTGOING CPAY DETAILS==\\n\")\n",
    "    return outgoing_cpay_settlement_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63d9167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dec69efd",
   "metadata": {},
   "source": [
    "### A function for generating OUTGOING_REVERSAL_DETAILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ef391e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_name_decorator\n",
    "def outgoing_reversal_details(filepath):\n",
    "    print(\"==\\nSTEPS FOR OUTGOING REVERSAL DETAILS\")\n",
    "    \n",
    "    print(\"STEP 1: Reading in the file for OUTGOING_REVERSAL_DETAILS...\")\n",
    "    df, has_no_header = read_report_file(filepath)\n",
    "    \n",
    "    if has_no_header:\n",
    "        print(\"STEP 2: Adding column names to the data\")\n",
    "        df = add_letter_columns_to_df(df)\n",
    "    \n",
    "    elif has_no_header == \"NA\":\n",
    "        warnings.warn(\"File was not found!\")\n",
    "        return \"\"\n",
    "    \n",
    "    print(\"STEP 3: Creating transaction amount by summing up column D \")\n",
    "    transaction_amount = abs(df[\"D\"].astype(float).sum()) * -1\n",
    "    \n",
    "    print(\"STEP 4: Creating the Narration dictionary\")\n",
    "    account = \"NGN09992527084\"\n",
    "    outgoing_reversal_details_dict = {\"ACCOUNT\": [account] * len(df),\n",
    "                                 \"AMOUNT\": [transaction_amount] * len(df),\n",
    "                                  \"NARRATION\": [f\"Outgoing Reversal {formatted_date}\"] * len(df)\n",
    "                                 }\n",
    "    \n",
    "    print(\"STEP 5: Creating the Narration DataFrame\")\n",
    "    outgoing_reversal_details_settlement_df = pd.DataFrame(outgoing_reversal_details_dict)\n",
    "    \n",
    "    #print(\"==END OF FUNCTION: OUTGOING REVERSAL DETAILS==\\n\")\n",
    "    return outgoing_reversal_details_settlement_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77752cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97ade404",
   "metadata": {},
   "source": [
    "### A function for generating OUTGOING_CARD_LOAD_DETAILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3d67a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_name_decorator\n",
    "def outgoing_cardloads_details(filepath):\n",
    "    \n",
    "    print(\"==STEPS FOR OUTGOING CARD LOAD==\")\n",
    "    \n",
    "    print(\"STEP 1: Reading in the file for OUTGOING_REVERSAL_DETAILS...\")\n",
    "    df, has_no_header = read_report_file(filepath)\n",
    "    \n",
    "    if has_no_header:\n",
    "        print(\"STEP 2: Adding column names to the data\")\n",
    "        df = add_letter_columns_to_df(df)\n",
    "     \n",
    "    elif has_no_header == \"NA\":\n",
    "        warnings.warn(\"File was not found!\")\n",
    "        return \"\"\n",
    "    \n",
    "    print(\"STEP 3: Summing column F by each category in column L\")\n",
    "    outgoing_card_load_details_settlement_df = df.groupby(\"L\").agg({\"F\": \"sum\"}).reset_index()\n",
    "    \n",
    "    print(\"STEP 4: Negating column F because it is outgoing\")\n",
    "    outgoing_card_load_details_settlement_df[\"F\"] = outgoing_card_load_details_settlement_df[\"F\"].apply(abs) * -1\n",
    "    \n",
    "    print(\"STEP 5: Adding the Narration column to the DataFrame\")\n",
    "    outgoing_card_load_details_settlement_df.loc[:, \"NARRATION\"] = f\"Outgoing Cardloads {formatted_date}\"\n",
    "    \n",
    "    print(\"STEP 6: Renaming the columns L and F to ACCOUNT and AMOUNT respectively\")\n",
    "    outgoing_card_load_details_settlement_df.rename(columns = {\"L\": \"ACCOUNT\", \"F\": \"AMOUNT\"}, inplace = True)\n",
    "    \n",
    "   # print(\"==END OF FUNCTION: OUTGOING CARD LOAD DETAILS==\\n\")\n",
    "    return outgoing_card_load_details_settlement_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f1f778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21932069",
   "metadata": {},
   "source": [
    "### A function for generating INCOMING PAYMENTS SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4721170",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_name_decorator\n",
    "def incoming_payments_summary(filepath):\n",
    "    \n",
    "    print(\"==STEPS FOR INCOMING PAYMENT SUMMARY\")\n",
    "    \n",
    "    print(\"STEP 1: Reading in the file for INCOMING PAYMENT SUMMARY...\")\n",
    "    df, has_no_header = read_report_file(filepath)\n",
    "    \n",
    "    if has_no_header:\n",
    "        print(\"STEP 2: Adding column names to the data\")\n",
    "        df = add_letter_columns_to_df(df)\n",
    "     \n",
    "    elif has_no_header == \"NA\":\n",
    "        warnings.warn(\"File was not found!\")\n",
    "        return \"\"\n",
    "    \n",
    "    print(\"STEP 3: Selecting just columns A and D\")\n",
    "    incoming_payments_summary_settlement_df = df[[\"A\", \"D\"]]\n",
    "\n",
    "    print(\"STEP 4: Finding the Net Settlement Position file\")\n",
    "    keyword = \"net_settlement_position\"\n",
    "    \n",
    "    \n",
    "    net_settlement_position_pdf_file_path = main_folder_path + _get_net_settlement_path(keyword, list_of_files)\n",
    "    print(main_folder_path)\n",
    "    print(net_settlement_position_pdf_file_path)\n",
    "    \n",
    "    print(\"STEP 5: Reading the batch ID from the Net Settlement PDF file\")\n",
    "    net_settlement_pdf_text = read_pdf(net_settlement_position_pdf_file_path)\n",
    "    net_settlement_data = net_settlement_pdf_text.split(\"Page\")[0]\n",
    "    print(net_settlement_data)\n",
    "    batch_id = net_settlement_data.split(\"Batch Id: \")[1].split()[0]\n",
    "    \n",
    "    print(\"STEP 6: Using the extracted batch ID to create the Narration column value\")\n",
    "    narration = batch_id + f\"{formatted_date}\" + \"IN PAYMENT\"\n",
    "    incoming_payments_summary_settlement_df.loc[:, \"NARRATION\"] = narration\n",
    "\n",
    "    print(\"STEP 7: Renaming columns A and D to ACCOUNT and AMOUNT\")\n",
    "    incoming_payments_summary_settlement_df.rename(columns = {\"A\": \"ACCOUNT\", \"D\": \"AMOUNT\"}, inplace = True)\n",
    "    \n",
    "    \n",
    "    #print(\"==END OF FUNCTION: GET INCOMING PAYMENTS SUMMARY==\\n\")\n",
    "    \n",
    "    return incoming_payments_summary_settlement_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db9a6ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "daf6814d",
   "metadata": {},
   "source": [
    "### A function for generating INCOMING CPAY DETAILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6efe9a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_name_decorator\n",
    "def incoming_cpay_details(filepath):\n",
    "    \n",
    "    print(\"==STEPS FOR INCOMING CPAY DETAILS==\")\n",
    "    \n",
    "    print(\"STEP 1: Reading in the file for INCOMING_CPAY_DETAILS...\")\n",
    "    df, has_no_header = read_report_file(filepath)\n",
    "    \n",
    "    if has_no_header:\n",
    "        print(\"STEP 2: Adding column names to the data\")\n",
    "        df = add_letter_columns_to_df(df)\n",
    "    \n",
    "    elif has_no_header == \"NA\":\n",
    "        warnings.warn(\"File was not found!\")\n",
    "        return \"\"\n",
    "    \n",
    "    print(\"STEP 3: Calculating the transaction amount\")\n",
    "    transaction_amount = df[\"TRANS_AMOUNT\"].astype(float).sum()\n",
    "    \n",
    "    print(\"STEP 4: Creating the Narration dictionary\")\n",
    "    incoming_cpay_dict = {\"ACCOUNT\": \"NGN09992508050\",\n",
    "                      \"AMOUNT\": transaction_amount,\n",
    "                      \"NARRATION\": f\"Incoming CorporatePay {formatted_date}\"\n",
    "                     }\n",
    "    \n",
    "    print(\"STEP 5: Creating the Narration DataFrame\")\n",
    "    incoming_cpay_details_settlement_df = pd.DataFrame(incoming_cpay_dict, index=[0])\n",
    "    \n",
    "    #print(\"==END OF FUNCTION: INCOMING CPAY DETAILS==\\n\")\n",
    "    \n",
    "    return incoming_cpay_details_settlement_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454167af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1310f39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cceb6a07",
   "metadata": {},
   "source": [
    "### A function for generating the Narration Template:\n",
    "\n",
    "This function is used by other functions to create the Narration Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f8ec1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_name_decorator\n",
    "def _create_narration_template():\n",
    "    \n",
    "    print(\"\\n==CREATING THE NARRATION TEMPLATE==\")\n",
    "    \n",
    "    print(\"STEP 1: Create template dictionary\")\n",
    "    narration_template_dict = {\n",
    "    \n",
    "    \"ACCOUNT\": [],\n",
    "    \"AMOUNT\": [],\n",
    "    \"NARRATION\": []\n",
    "    }\n",
    "    \n",
    "    print(\"STEP 2: Create template DataFrame\")\n",
    "    narration_template_df = pd.DataFrame(narration_template_dict)\n",
    "    \n",
    "    return narration_template_df\n",
    "\n",
    "# narration_template_df = _create_narration_template()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917cc625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "492b4202",
   "metadata": {},
   "source": [
    "### A function for compiling DataFrames:\n",
    "\n",
    "The function is used for creating a DataFrames and its output is a combination of different DataFrames. It is used for compiling all the DataFrames generated during the transformations undergone in the functions defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f228f704",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_name_decorator\n",
    "def compile_dataframes(*dframes):\n",
    "    \n",
    "    print(\"==COMPILING THE SETTLEMENT DATAFRAMES==\")\n",
    "    \n",
    "    print(\"STEP 1: Calling the create function to create Template\")\n",
    "    template_df = _create_narration_template()\n",
    "    \n",
    "    print(\"Compiling all the templates into 1 DataFrame\")\n",
    "    narrations_df = pd.concat(dframes)\n",
    "    \n",
    "    return narrations_df\n",
    "\n",
    "# narrations_df = compile_dataframes(narration_template_df, outgoing_commission_summary_df, \n",
    "#           incoming_transfer_details_df, babcock_incoming_commissions_details_df, incoming_commissions_summary_df,\n",
    "#               samebank_commissions_summary_df)\n",
    "\n",
    "# narrations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91010c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03b6be75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_net_settlement_values(list_of_files, main_folder_path):\n",
    "    \n",
    "    print(\"==COLLECTING ALL THE VALUES IN THE NET SETTLEMENT POSITION PDF\")\n",
    "    \n",
    "    print(\"STEP 1: Getting the filename of the Net Settlement Position\")\n",
    "    filename = _get_net_settlement_path(\"net_settlement\", list_of_files)\n",
    "    \n",
    "    print(\"STEP 2: Creating the full path for the Net Settlement Position\")\n",
    "    filepath = main_folder_path + filename\n",
    "\n",
    "    print(\"STEP 3: Reading the Net Settlement PDF file\")\n",
    "    net_settlement_content = read_pdf(filepath)\n",
    "\n",
    "    print(\"STEP 4: Creating a list of values in the Net Settlement Position PDF file\")\n",
    "    net_settlement_list = net_settlement_content.split()\n",
    "\n",
    "    net_settlement_list = [_convert_string_numbers(content, mute = True) for content in net_settlement_list]\n",
    "    \n",
    "    net_settlement_list = [content for content in net_settlement_list if content != \"Not a number\"]\n",
    "    \n",
    "    print(\"STEP 5: Returning the list of values extracted.\")\n",
    "    \n",
    "    return net_settlement_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e6b7de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "227a6ce6",
   "metadata": {},
   "source": [
    "### A function to extract Settlement Position:\n",
    "\n",
    "This function is used to extract the Settlement Position from the correct Settlement PDF file and returns this value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad510ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_name_decorator\n",
    "def _extract_settlement_position(filepath):\n",
    "    \n",
    "    print(\"==EXTRACTING THE SETTLEMENT POSITION\")\n",
    "    pdf_text = read_pdf(filepath)\n",
    "    \n",
    "    print(\"STEP 1: Extracting the necessary text from the pdf file\")\n",
    "    net_settlement_data = pdf_text.split(\"Page\")[0]\n",
    "    \n",
    "    print(\"STEP 2: Converting the extracted text into an IO object\")\n",
    "    data_io = StringIO(net_settlement_data)\n",
    "\n",
    "    print(\"STEP 3: Read the data as a DataFrame\")\n",
    "    net_settlement_df = pd.read_csv(data_io, delim_whitespace=True, skiprows=2, header=None)\n",
    "    \n",
    "    print(\"STEP 4: Extracting the Total Incoming and Outgoing Amounts.\")\n",
    "    try:\n",
    "        total_incoming_amount = _convert_string_numbers(net_settlement_df[0].to_list()[:-1][-1], mute = True)\n",
    "\n",
    "        total_outgoing_amount = _convert_string_numbers(net_settlement_df[1].to_list()[:-1][-1], mute = True)\n",
    "        print(f\"\\nTotal Incoming Amount in Net Settlement PDF = {total_incoming_amount} \")\n",
    "        print(f\"Total Outgoing Amount in Net Settlement PDF = {total_outgoing_amount}\\n\")\n",
    "    \n",
    "    except IndexError as e:\n",
    "        warnings.warn(\"Couldn't extract Total Incoming and Outgoing Amounts. Perhaps file structure has changed!\")\n",
    "        print(\"Equating them to empty strings\")\n",
    "        total_incoming_amount = \"\"\n",
    "        total_outgoing_amount = \"\"\n",
    "    \n",
    "    print(\"STEP 5: Extracting Settlement Position\")\n",
    "    try:\n",
    "        settlement_position = round(convert_string_numbers(net_settlement_df[2].to_list()[:-1][-1]), 2)\n",
    "        \n",
    "    except IndexError as e:\n",
    "        warnings.warn(\"Couldn't extract Settlement Position. Perhaps file structure has changed!\")\n",
    "        print(\"Equating Settlement Position to an empty string and returning it\")\n",
    "        settlement_position = \"\"\n",
    "        return settlement_position\n",
    "    \n",
    "    print(\"STEP 6: Checking if there was an issue with the values extracted in Steps 3 and 4\")\n",
    "    if total_incoming_amount == \"\" or total_outgoing_amount == \"\":\n",
    "        return settlement_position\n",
    "    \n",
    "    print(\"STEP 7: Calculating the Settlement Position from the Total Incoming and Outgoing Amounts extracted\")\n",
    "    print(f\"{total_incoming_amount} - {total_outgoing_amount}\")\n",
    "    calculated_settlement_position = round(total_incoming_amount - total_outgoing_amount, 2)\n",
    "    print(f\"Calculated Settlement Position = {calculated_settlement_position}\")\n",
    "    print(f\"Actual Settlement Position = {settlement_position}\")\n",
    "    \n",
    "    print(\"STEP 8: Checking if this calculated Settlement Position is equal to the extracted Settlement Position\")\n",
    "    if calculated_settlement_position == settlement_position:\n",
    "        print(\"STEP 9: Net Settlement Position Confirmed! Returning the value\")\n",
    "        return settlement_position\n",
    "    \n",
    "    else:\n",
    "        print(\"STEP 9: Net Settlement Position was NOT confirmed.\")\n",
    "        warnings.warn(\"Calculated settlement is NOT equal to extracted settlement. Perhaps file structure has changed!\")\n",
    "        print(f\"\\nReturning settlement position: {settlement_position}. Check that it is correct\")\n",
    "        return settlement_position\n",
    "    \n",
    "    return net_settlement_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9242c497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f93294e6",
   "metadata": {},
   "source": [
    "### A function that maps Report to their respective function:\n",
    "\n",
    "This function returns a mapping of each Report and the corresponding Function that is to handle them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0d3d32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_of_files = list_of_files_generator(main_folder_path)\n",
    "\n",
    "@function_name_decorator\n",
    "def file_to_function_mapping(list_of_files):\n",
    "    \n",
    "    file_function_mapping = {}\n",
    "    if len(list_of_files) == 0:\n",
    "        warnings.warn(\"\\nNo files were detected! No file to function mapping possible\")\n",
    "        return \"\"\n",
    "    \n",
    "    for prospect_report_name in reports_keywords_dict.keys():\n",
    "        for report_name in list_of_files:\n",
    "            if report_name.lower().find(prospect_report_name.lower()) > 0:\n",
    "                if \"comm_summary_detail\" in report_name.lower():\n",
    "                    if report_name.lower().endswith(\".csv\") or report_name.lower().endswith(\".xls\") or report_name.lower().endswith(\".xlsx\"):\n",
    "                        print(f\"Report found\\nReport name: {report_name}\")\n",
    "                        #print(f\"{report_name}  { reports_keywords_dict[prospect_report_name].__name__}\")\n",
    "                        file_function_mapping[report_name] = reports_keywords_dict[prospect_report_name]\n",
    "                \n",
    "                elif \"summary_detail\" in report_name.lower():\n",
    "                    continue\n",
    "                \n",
    "                else:\n",
    "                    if report_name.lower().endswith(\".csv\") or report_name.lower().endswith(\".xls\") or report_name.lower().endswith(\".xlsx\"):\n",
    "                        print(f\"Report found\\nReport name: {report_name}\")\n",
    "                        #print(f\"{report_name}  { reports_keywords_dict[prospect_report_name].__name__}\")\n",
    "                        file_function_mapping[report_name] = reports_keywords_dict[prospect_report_name]\n",
    "                    \n",
    "                \n",
    "    return file_function_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8bf4e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9f00b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_name_decorator\n",
    "def supplementary_file_to_function_mapping(list_of_files):\n",
    "    \n",
    "    file_function_mapping = {}\n",
    "    if len(list_of_files) == 0:\n",
    "        warnings.warn(\"\\nNo files were detected! No file to function mapping possible\")\n",
    "        return \"\"\n",
    "    \n",
    "    for prospect_report_name in supplementary_reports_keywords_dict.keys():\n",
    "        for report_name in list_of_files:\n",
    "            if report_name.lower().find(prospect_report_name.lower()) > 0:\n",
    "                if \"comm_summary_detail\" in report_name.lower():\n",
    "                    if report_name.lower().endswith(\".pdf\"):\n",
    "                        print(f\"Report found\\nReport name: {report_name}\")\n",
    "                        #print(f\"{report_name}  { reports_keywords_dict[prospect_report_name].__name__}\")\n",
    "                        file_function_mapping[report_name] = reports_keywords_dict[prospect_report_name]\n",
    "                \n",
    "                elif \"summary_detail\" in report_name.lower():\n",
    "                    continue\n",
    "                \n",
    "                else:\n",
    "                    if report_name.lower().endswith(\".pdf\"):\n",
    "                        print(f\"Report found\\nReport name: {report_name}\")\n",
    "                        #print(f\"{report_name}  { reports_keywords_dict[prospect_report_name].__name__}\")\n",
    "                        file_function_mapping[report_name] = supplementary_reports_keywords_dict[prospect_report_name]\n",
    "                    \n",
    "                \n",
    "    return file_function_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c5ed62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfafc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_name_decorator\n",
    "def get_alternative_report_name(filename):\n",
    "    \n",
    "    print(f\"==CALCULATING NEW SETTLEMENT FOR {filename} FROM ANOTHER REPORT\")\n",
    "    \n",
    "    print(\"STEP 1: Replace 'DETAILS' with 'SUMMARY' and replace file extension with 'PDF'\")\n",
    "    new_filename = filename.replace(\"DETAILS\", \"SUMMARY\").split(\".\")[0] + \".PDF\"\n",
    "    \n",
    "    print(\"STEP 2: Checking if the New filename exists\")\n",
    "    if new_filename in list_of_files:\n",
    "        full_path = main_folder_path + new_filename\n",
    "        print(f\"Filename {new_filename} exists!\")\n",
    "        \n",
    "    elif \"AM\" not in new_filename or \"PM\" not in new_filename:\n",
    "        am_pm = _get_folder_hour(main_folder_path)[-2:]\n",
    "        new_filename = new_filename.split(\".\")[0] + \"_\" + am_pm + \".PDF\"\n",
    "        if new_filename in list_of_files:\n",
    "            print(f\"Filename {new_filename} exists!\")\n",
    "        \n",
    "    return new_filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b87e961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde59d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_name_decorator\n",
    "def alternative_settlement_process(new_filename):\n",
    "    \n",
    "    print(f\"==\\nSETTLEMENT PROCESS FOR NEW FILE: {new_filename}\")\n",
    "    \n",
    "    print(\"STEP 1: Creating the full path for the new file\")\n",
    "    full_path = main_folder_path + new_filename\n",
    "    print(f\"Full path to file: {full_path}\")\n",
    "    \n",
    "    print(\"STEP 2: Creating the file-to-function mapping\")\n",
    "    workflow_dict = supplementary_file_to_function_mapping(list_of_files)\n",
    "    \n",
    "    print(\"STEP 3: Getting the function assigned to the new file\")\n",
    "    narration_function = workflow_dict[new_filename]\n",
    "    \n",
    "    print(\"STEP 4: Applying the narration function to the file\")\n",
    "    narration = narration_function(full_path)\n",
    "    \n",
    "    if isinstance(narration, str):\n",
    "        warnings.warn(f\"File was NOT processed because it was not found.\\nFilename: {filename}\")\n",
    "        \n",
    "        \n",
    "    return narration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259d3fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6661547f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# workflow_dict = file_to_function_mapping(list_of_files)\n",
    "# worklfow_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d195a9d",
   "metadata": {},
   "source": [
    "### Create a Final Narration DataFrame:\n",
    "\n",
    "This function creates a Narration DataFrame which is combination of all the generated DataFrames. It uses the dictionary/mapping created using the file_to_function_mapping to run each file against their transformation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84224e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_name_decorator\n",
    "def generate_narration_batch_compilation(workflow_dict, main_folder_path):\n",
    "    \n",
    "    folder_hour = _get_folder_hour(main_folder_path)\n",
    "    \n",
    "    print(f\"\\n==GENERATING COMPILED NARRATION FOR {folder_hour}\")\n",
    "    \n",
    "    if workflow_dict == \"\":\n",
    "        warnings.warn(\"\\nNo file to function mapping. No compiled report possible\")\n",
    "        return \"\"\n",
    "    \n",
    "    print(\"STEP 1: Initialize the Narration list that holds all the Narration DataFrames.\\nAlso getting all values in Net Settlement Position PDF\")\n",
    "    narration_list = []\n",
    "    files_worked_on =[]\n",
    "    settlement_values_list = _get_net_settlement_values(list_of_files, main_folder_path)\n",
    "    \n",
    "    print(\"\\nSTEP 2: Looping through each Identified Report stored in the workflow_dict\")\n",
    "    for filenum, filename in enumerate(workflow_dict.keys()):\n",
    "        \n",
    "        print(f\"\\n\\nBEGINNING TRANSFORMATION FOR {filename}\")\n",
    "        print(f\"    STEP 2.1.{filenum}: Creating the full path for the file. It will include {folder_hour}/ in front of the filename\")\n",
    "        full_path = main_folder_path + filename\n",
    "        print(full_path)\n",
    "\n",
    "        print(f\"    STEP 2.2.{filenum}: Getting the function responsible for cleaning the filename {filename}\")\n",
    "        narration_function = workflow_dict[filename]\n",
    "        \n",
    "        print(f\"    STEP 2.3.{filenum}: Running the Narration function on the file\")\n",
    "        narration = narration_function(full_path)\n",
    "        \n",
    "        if isinstance(narration, str):\n",
    "            warnings.warn(f\"File was NOT processed because it was not found.\\nFilename: {filename}\")\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        print(\"\\nREPORT FILE NAME : TOTAL AMOUNT CALCULATED\")\n",
    "        narration_total = round(narration['AMOUNT'].astype(float).sum(), 2)\n",
    "        print(f\"{filename}: {narration_total}\")\n",
    "        \n",
    "        if \"incoming_commissions_summary\" in filename.lower() or \"incoming_commissions_details\" in filename.lower():\n",
    "            print(f\"No checks necessary. Filename: {filename}\")\n",
    "            files_worked_on.append(filename)\n",
    "            narration_list.append(narration)\n",
    "        \n",
    "        else:\n",
    "            print(f\"STEP 3: Checking if Narration total is on the Settlement Position created earlier\")\n",
    "            \n",
    "            if abs(narration_total) in settlement_values_list:\n",
    "                print(f\"{filename} settlement confirmed from Net Settlement Postion PDF\")\n",
    "                print(f\"STEP 4.{filenum}: Appending the DataFrame generated by the function to the Narration list created earlier\")\n",
    "                narration_list.append(narration)\n",
    "                files_worked_on.append(filename)\n",
    "                print(narration)\n",
    "\n",
    "\n",
    "            else:\n",
    "                warnings.warn(f\"{filename} settlement NOT confirmed from Net Settlement Postion PDF\")\n",
    "                print(f\"{filename} settlement NOT confirmed. Checking for alternative among other provided documents\")\n",
    "                new_name = get_alternative_report_name(filename)\n",
    "                narration = alternative_settlement_process(new_name)\n",
    "                print(narration)\n",
    "                print(\"\\nREPORT FILE NAME : NEW TOTAL AMOUNT CALCULATED\")\n",
    "                narration_total = round(narration['AMOUNT'].astype(float).sum(), 2)\n",
    "                print(f\"{filename}: {narration_total}\")\n",
    "                if abs(narration_total) in settlement_values_list:\n",
    "                    print(f\"{filename} settlement confirmed from Net Settlement Postion PDF on Second Attempt\")\n",
    "                    print(f\"STEP 4.{filenum}: Appending the DataFrame generated by the function to the Narration list created earlier\")\n",
    "                    narration_list.append(narration)\n",
    "                    files_worked_on.append(filename)\n",
    "                    print(narration)\n",
    "\n",
    "                else:\n",
    "                    warnings.warn(f\"{filename} settlement NOT confirmed from Net Settlement Postion PDF after 2nd attempt\")\n",
    "                    print(f\"This report: {filename} will not be considered in the final entries\")\n",
    "                    files_worked_on.append(filename)\n",
    "        \n",
    "    print(\"\\n\\nCompiling all the DataFrames to 1 compiled narration\")\n",
    "    print(f\"Files worked on are: {files_worked_on}\\n\")\n",
    "    \n",
    "    if len(files_worked_on) != len(narration_list):\n",
    "        warnings.warn(\"Not all files were processed. Calculations will most likely be wrong because 1 or more files are missing from the compiled report, or file contains incomplete values\")\n",
    "        print(f\"Number of files worked on: {len(files_worked_on)}.\\nNumber of Dataframes: {len(narration_list)}\")\n",
    "    else:\n",
    "        print(f\"Number of files worked on: {len(files_worked_on)}.\\nNumber of Dataframes: {len(narration_list)}\")\n",
    "    try:\n",
    "        narrations_df = pd.concat(narration_list)\n",
    "        \n",
    "    except ValueError as e:\n",
    "        print(f\"\\nThere are no files to process. Perhaps there are no files in the path provided.\\nPython error: {e}\")\n",
    "        narrations_df = \"\"\n",
    "        \n",
    "    return narrations_df\n",
    "\n",
    "\n",
    "# narrations_df = generate_narration_batch_compilation(workflow_dict)\n",
    "# narrations_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847c6caa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aabea4d4",
   "metadata": {},
   "source": [
    "### A function for comparing Transformation and Settlement Position:\n",
    "\n",
    "This is a function for comparing the result of the sum from the final value in the Transformation with the value extracted from the Net Settlement PDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "431eae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_name_decorator\n",
    "def compare_total_settlement_total_narration(narrations_df, main_folder_path):\n",
    "    \n",
    "    print(\"\\n==COMPARING THE TOTAL SETTLEMENT POSITION WITH THE COMPILED NARRATION\")\n",
    "    \n",
    "    if isinstance(narrations_df, str):\n",
    "        warnings.warn(\"There is no compiled report to compare with settlement position\")\n",
    "        return \"NA\"\n",
    "    \n",
    "    print(\"STEP 1: Summing the complete narration values under the AMOUNT column\")\n",
    "    total_narration_value = narrations_df[\"AMOUNT\"].sum()\n",
    "    total_narration_value = round(total_narration_value, 2)\n",
    "    print(f\"AMOUNT = {total_narration_value}\")\n",
    "    \n",
    "    print(\"\\nSTEP 2: Getting the Path for the Net Settlement Position\")\n",
    "#     net_settlement_position_pdf_file_path = main_folder_path\n",
    "#     net_settlement_position_pdf_file_path += _convert_hour_to_am_pm(current_hour, for_folder= True)\n",
    "    net_settlement_position_pdf_file_path = main_folder_path + _get_net_settlement_path(\"net_settlement_position\", list_of_files)\n",
    "    print(f\"Net Settlement Position Path: {net_settlement_position_pdf_file_path}\")\n",
    "    \n",
    "    print(f\"\\n\\nSTEP 3: Extracting the settlement position value from the NET_SETTLEMENT pdf file\")\n",
    "    net_settlement_value = _extract_settlement_position(net_settlement_position_pdf_file_path)\n",
    "    \n",
    "    print(f\"\\n\\nBack to Comparing Net Settlement Value with the Calculated Amount\")\n",
    "    print(f\"Net settlement value from PDF = {net_settlement_value}\")\n",
    "    print(f\"Total Narration value from calculation = {total_narration_value}\")\n",
    "    \n",
    "    print(\"STEP 4: Calculating the Balance. This must be ZERO\")\n",
    "    print(f\"{net_settlement_value} - {total_narration_value}\")\n",
    "    balance = net_settlement_value - total_narration_value\n",
    "    balance = round(balance, 2)\n",
    "    \n",
    "    if balance == 0:\n",
    "        print(\"Check complete. Balance is correct\")\n",
    "        print(f\"Balance = {balance}\")\n",
    "        \n",
    "    else:\n",
    "        warnings.warn(\"Check complete but Balance is INCORRECT.\")\n",
    "        print(f\"Balance = {balance}\")\n",
    "        \n",
    "    return balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e43b8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f8d14ef",
   "metadata": {},
   "source": [
    "### A function for raising entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ae6db5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_of_raising_entries(dframe):\n",
    "    print(\"==RAISING ENTRIES==\")\n",
    "    \n",
    "    if isinstance(dframe, str):\n",
    "        warnings.warn(\"Final DataFrame is a string. Cannot provide any output.\")\n",
    "        return \"NA\"\n",
    "    \n",
    "    print(\"STEP 1: Make a copy of the DataFrame\")\n",
    "    df = dframe.copy()\n",
    "    \n",
    "    print(\"STEP 2: Sort all the values by the AMOUNT column\")\n",
    "    df = df.sort_values(\"AMOUNT\")\n",
    "    \n",
    "    print(\"STEP 3: Limit the NARRATION column width to 30 characters. All other columns are separated by 10 characters\")\n",
    "    \n",
    "    df[\"NARRATION\"] = df[\"NARRATION\"].str[:30]\n",
    "    \n",
    "    \n",
    "    print(\"STEP 4: Add an extra column to the end of the DataFrame because we are about to insert an empty column\")\n",
    "    df = _create_inner_columns(df, 2, \"NARRATION\")\n",
    "    \n",
    "    \n",
    "    print(\"STEP 5: Placing the Transaction ID (i.e. 'C' or 'D') in a column 2 columns away from 'NARRATION'\")\n",
    "    df.loc[:, \"E\"] = np.where(df[\"AMOUNT\"] < 0, \"D\", \"C\")\n",
    "    \n",
    "    print(\"STEP 6: Reorder the data by ACCOUNT\")\n",
    "    df[\"ACCOUNT\"] = df[\"ACCOUNT\"].astype(str)\n",
    "    df = df.sort_values(\"ACCOUNT\")\n",
    "    \n",
    "    print(\"STEP 7: Selecting a portion of the Data where the ACCOUNT starts with 'PAL0999'\")\n",
    "    pal_df = df.loc[df[\"ACCOUNT\"].astype(str).str.startswith(\"PAL0999\"), :]\n",
    "    \n",
    "    #print(\"\\nIf this selected DataFrame is empty, then return the result of the transformation so far. Else, continue the transformations\")\n",
    "    if pal_df.empty:\n",
    "        print(\"There is no PAL account. Entries complete!\")\n",
    "\n",
    "        print(\"STEP 8: Deleting column D\")\n",
    "        final_df = df.drop(\"D\", axis = 1)\n",
    "\n",
    "        print(\"STEP 9: Renaming column E to TRANSACTION TYPE\")\n",
    "        final_df.rename(columns = {\"E\": \"TRANSACTION TYPE\"}, inplace = True)\n",
    "        #final_df = final_df[[\"ACCOUNT\", \"AMOUNT\", \"NARRATION\"]]\n",
    "        print(\"\\nEntries complete!\")\n",
    "       # print(\"\\n==END OF FUNCTION: PROCESS OF RAISING ENTRIES==\")\n",
    "        return final_df\n",
    "    \n",
    "    else:\n",
    "        print(\"STEP 8: Create copies of the smaller DataFrame so you can use them to compute VAT on the PAL account\")\n",
    "        calc_df = pal_df.copy()\n",
    "        vat_df = pal_df.copy()\n",
    "        print(\"Calc df before transformation:\\n\")\n",
    "        print(calc_df)\n",
    "        \n",
    "        print(\"Vat df before transformation:\\n\")\n",
    "        print(vat_df)\n",
    "        \n",
    "        print(\"STEP 9: Calculating the VAT amount\")\n",
    "        calc_df[\"AMOUNT\"] = calc_df[\"AMOUNT\"]*0.9302\n",
    "        vat_df[\"AMOUNT\"] = vat_df[\"AMOUNT\"] - vat_df[\"AMOUNT\"]*0.9302\n",
    "        vat_df[\"ACCOUNT\"] = vat_df[\"ACCOUNT\"].apply(lambda x: \"NGN09992511001\" if x.startswith(\"PAL0999\") else x)\n",
    "        \n",
    "        print(\"Calc df after transformation:\\n\")\n",
    "        print(calc_df)\n",
    "        \n",
    "        print(\"Vat df after transformation:\\n\")\n",
    "        print(vat_df)\n",
    "        \n",
    "        print(\"STEP 10: Updating the original DataFrame with the new values in the AMOUNT column\")\n",
    "        df.update(calc_df)\n",
    "        \n",
    "        print(\"STEP 11: Updating the original DataFrame with the new values in the AMOUNT (VAT) and ACCOUNT columns\")\n",
    "        final_df = pd.concat([df, vat_df])\n",
    "        final_df = final_df.drop(\"D\", axis = 1)\n",
    "\n",
    "        print(\"STEP 12: Renaming column E to TRANSACTION TYPE\")\n",
    "        final_df.rename(columns = {\"E\": \"TRANSACTION TYPE\"}, inplace = True)\n",
    "        #final_df = final_df[[\"ACCOUNT\", \"AMOUNT\", \"NARRATION\"]]\n",
    "        print(\"\\nEntries complete!\")\n",
    "        #print(\"\\n==END OF FUNCTION: PROCESS OF RAISING ENTRIES==\")\n",
    "        return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393c0673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b10000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58fed5d2",
   "metadata": {},
   "source": [
    "### Additional functions not discussed in process documentation. \n",
    "\n",
    "#### These are used when there is any inaccurate balance after running any of the functions above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ad9289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outgoing_reversal_summary(filepath):\n",
    "    \n",
    "    file = read_pdf(filepath)\n",
    "    \n",
    "    data = file.split(\"Page\")[0]\n",
    "    \n",
    "    print(\"STEP 2: Converting the extracted text into an IO object\")\n",
    "    data_io = StringIO(data)\n",
    "\n",
    "    print(\"STEP 3: Read the data as a DataFrame\")\n",
    "    df = pd.read_csv(data_io, delim_whitespace=True, skiprows=2, header=None)\n",
    "\n",
    "    longest_col_length = 0\n",
    "    longest_col = None\n",
    "    for col in net_settlement_df.columns:\n",
    "\n",
    "        col_length = len(net_settlement_df[col].dropna())\n",
    "        if col_length > longest_col_length:\n",
    "            longest_col_length = col_length\n",
    "            longest_col = col\n",
    "        \n",
    "    transaction_amount = net_settlement_df[longest_col].to_list()[-1]\n",
    "    \n",
    "    transaction_amount = convert_string_numbers(transaction_amount)\n",
    "    transaction_amount = abs(transaction_amount)* -1\n",
    "    \n",
    "    print(\"STEP 4: Creating the Narration dictionary\")\n",
    "    account = \"NGN09992527084\"\n",
    "    outgoing_reversal_details_dict = {\"ACCOUNT\": [account],\n",
    "                                 \"AMOUNT\": [transaction_amount],\n",
    "                                  \"NARRATION\": [f\"Outgoing Reversal {formatted_date}\"]\n",
    "                                 }\n",
    "    \n",
    "    print(\"STEP 5: Creating the Narration DataFrame\")\n",
    "    outgoing_reversal_details_settlement_df = pd.DataFrame(outgoing_reversal_details_dict)\n",
    "    \n",
    "    #print(\"==END OF FUNCTION: OUTGOING REVERSAL DETAILS==\\n\")\n",
    "    return outgoing_reversal_details_settlement_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76ecabc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d841833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef07021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def incoming_cpay_summary(filepath):\n",
    "    \n",
    "    file = read_pdf(filepath)\n",
    "    data = file.split(\"Page\")[0]\n",
    "\n",
    "    print(\"STEP 2: Converting the extracted text into an IO object\")\n",
    "    data_io = StringIO(data)\n",
    "\n",
    "    print(\"STEP 3: Read the data as a DataFrame\")\n",
    "    df = pd.read_csv(data_io, delim_whitespace=True, skiprows=1, header=None)\n",
    "    longest_col_length = 0\n",
    "    longest_col = None\n",
    "    for col in df.columns:\n",
    "\n",
    "        col_length = len(df[col].dropna())\n",
    "        if col_length > longest_col_length:\n",
    "            longest_col_length = col_length\n",
    "            longest_col = col\n",
    "\n",
    "    col_values = df[longest_col].to_list()\n",
    "\n",
    "    transaction_amount = [total for total in col_values if \"/\" not in total][-1]\n",
    "    transaction_amount = convert_string_numbers(transaction_amount)\n",
    "    \n",
    "    print(\"STEP 4: Creating the Narration dictionary\")\n",
    "    incoming_cpay_dict = {\"ACCOUNT\": \"NGN09992508050\",\n",
    "                      \"AMOUNT\": transaction_amount,\n",
    "                      \"NARRATION\": f\"Incoming CorporatePay {formatted_date}\"\n",
    "                     }\n",
    "    \n",
    "    print(\"STEP 5: Creating the Narration DataFrame\")\n",
    "    incoming_cpay_details_settlement_df = pd.DataFrame(incoming_cpay_dict, index=[0])\n",
    "    \n",
    "    #print(\"==END OF FUNCTION: INCOMING CPAY DETAILS==\\n\")\n",
    "    \n",
    "    return incoming_cpay_details_settlement_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507c6d22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2efa295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeb9712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def incoming_transfer_summary(filepath):\n",
    "    \n",
    "    file = read_pdf(filepath)\n",
    "    data = file.split(\"Total\")[1]\n",
    "    print(data)\n",
    "    print(\"STEP 2: Converting the extracted text into an IO object\")\n",
    "    data_io = StringIO(data)\n",
    "\n",
    "    print(\"STEP 3: Read the data as a DataFrame\")\n",
    "    df = pd.read_csv(data_io, delim_whitespace=True, skiprows=1, header=None)\n",
    "    print(df)\n",
    "    longest_col_length = 0\n",
    "    longest_col = None\n",
    "    for col in df.columns:\n",
    "\n",
    "        col_length = len(df[col].dropna())\n",
    "        if col_length > longest_col_length:\n",
    "            longest_col_length = col_length\n",
    "            longest_col = col\n",
    "            \n",
    "        if \"account\" in df[col].str.lower().to_list():\n",
    "            col_list = df[col].to_list()\n",
    "            col_idx = df.columns.tolist().index(col)\n",
    "            target_idx = col_idx + 1\n",
    "            all_cols = df.columns\n",
    "            target_col = all_cols[target_idx]\n",
    "            account_num = df[target_col].dropna().to_list()[-1]\n",
    "\n",
    "    col_values = df[longest_col].to_list()\n",
    "\n",
    "    transaction_amount = [total for total in col_values if \"/\" not in total][-1]\n",
    "    auto_sum = convert_string_numbers(transaction_amount)\n",
    "    \n",
    "    print(\"STEP 5: Create a dictionary for the Account extracted and Amount calculated\")\n",
    "    auto_sum_acct_num_dict = {\n",
    "    \n",
    "   \"ACCOUNT\": [account_num],\n",
    "    \"AMOUNT\": [auto_sum]\n",
    "    }\n",
    "    \n",
    "    print(\"STEP 6: Convert the dictionary into a DataFrame\")\n",
    "    income_transfer_settlement_df = pd.DataFrame(auto_sum_acct_num_dict)\n",
    "\n",
    "    print(\"STEP 7: Including the NARRATION in the DataFrame\")\n",
    "    income_transfer_settlement_df [\"NARRATION\"] = f\"Incoming Transfers {formatted_date} S1\"\n",
    "    \n",
    "    #print(\"==END OF FUNCTION: INCOMING TRANSFER DETAILS==\\n\")\n",
    "    return income_transfer_settlement_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07392e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001027fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafbf835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outgoing_cardloads_summary(filepath):\n",
    "    import re\n",
    "    file = read_pdf(filepath)\n",
    "    data = file.split(\"Pages\")[0].split(\"\\n\")\n",
    "    print(data[8])\n",
    "    ngn_pattern = r'NGN(\\d+)'#NGN(\\d+)\\s.*?(\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?)'\n",
    "    amount_pattern = r'\\b(\\d{1,3}(,\\d{3})*(\\.\\d+)?)\\b'\n",
    "    accounts_list = []\n",
    "    amounts_list = []\n",
    "    for line in data:\n",
    "        ngn_match = re.findall(ngn_pattern, line)\n",
    "        amount_match = re.findall(amount_pattern, line)\n",
    "        \n",
    "        ngn_code = 0\n",
    "        amount = 0\n",
    "        amount_value = \"\"\n",
    "    \n",
    "        if ngn_match and amount_match:\n",
    "            accounts_list.append(\"NGN\"+str(ngn_match[0]))\n",
    "            \n",
    "            #print(line)\n",
    "            numerical_values = [float(value.replace(',', '')) for value in line.split() if value.replace(',', '').replace('.', '').isdigit()]\n",
    "                \n",
    "            largest_number = max(numerical_values, default=None)\n",
    "            #print(largest_number)\n",
    "            \n",
    "            amounts_list.append(largest_number)\n",
    "            \n",
    "    print(accounts_list)\n",
    "    print(amounts_list)\n",
    "    \n",
    "    amounts_list = [-value for value in amounts_list]\n",
    "    \n",
    "    outgoing_cardload_dict = {\"ACCOUNT\": accounts_list, \"AMOUNT\": amounts_list, \n",
    "                              \"NARRATION\": [f\"Outgoing Cardloads {formatted_date}\"] * len(accounts_list)}\n",
    "    \n",
    "    outgoing_cardload_df = pd.DataFrame(outgoing_cardload_dict)\n",
    "    \n",
    "    return outgoing_cardload_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c24d2c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775cab74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b64fb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def incoming_reversal_summary(filepath):\n",
    "    \n",
    "    file = read_pdf(filepath)\n",
    "    data = file.split(\"Pages\")[0]\n",
    "    \n",
    "    data_io = StringIO(data)\n",
    "\n",
    "    print(\"STEP 3: Read the data as a DataFrame\")\n",
    "    df = pd.read_csv(data_io, delim_whitespace=True, skiprows=0, header=None)\n",
    "    \n",
    "    longest_col_length = 0\n",
    "    longest_col = None\n",
    "    for col in df.columns:\n",
    "\n",
    "        col_length = len(df[col].dropna())\n",
    "        if col_length > longest_col_length:\n",
    "            longest_col_length = col_length\n",
    "            longest_col = col\n",
    "\n",
    "    col_values = df[longest_col].to_list()\n",
    "\n",
    "    transaction_amount = [total for total in col_values if \"/\" not in total][-1]\n",
    "    transaction_amount = convert_string_numbers(transaction_amount)\n",
    "    \n",
    "    print(\"STEP 4: Creating a dictionary for the Narration\")\n",
    "    incoming_reversal_dict = {\"ACCOUNT\": [\"NGN09992501102\"],\n",
    "                          \"AMOUNT\": [transaction_amount],\n",
    "                          \"NARRATION\": [f\"Incoming Reversal {formatted_date}\"]\n",
    "                         }\n",
    "    \n",
    "    print(\"STEP 5: Converting the dictionary to a DataFrame\")\n",
    "    incoming_reversal_settlement_df = pd.DataFrame(incoming_reversal_dict)\n",
    "    \n",
    "    #print(\"==END OF FUNCTION: INCOMING REVERSAL DETAILS==\\n\")\n",
    "    \n",
    "    return incoming_reversal_settlement_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50784eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160486d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6a6ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outgoing_cpay_summary(filepath):\n",
    "    \n",
    "    file = read_pdf(filepath)\n",
    "    \n",
    "    data_list = file.split(\"Total\")\n",
    "    list_of_targets = []\n",
    "    for data in data_list:\n",
    "        list_of_strings = data.split()\n",
    "    \n",
    "        for i, strings in enumerate(list_of_strings):\n",
    "    \n",
    "            try:\n",
    "                target_value = re.findall(r'\\b(\\d{1,3}(,\\d{3})*(\\.\\d+)?)\\b', strings)[0][0]\n",
    "                list_of_targets.append(target_value)\n",
    "                \n",
    "            except IndexError as e:\n",
    "                if i < 1:\n",
    "                    print(e)\n",
    "                continue\n",
    "    \n",
    "    largest_target = 0\n",
    "    for potential_target in list_of_targets:\n",
    "        potential_target = _convert_string_numbers(potential_target)\n",
    "        if potential_target > largest_target:\n",
    "            largest_target = potential_target\n",
    "            \n",
    "        \n",
    "    transaction_amount = convert_string_numbers(largest_target)\n",
    "    transaction_amount = abs(transaction_amount) * -1\n",
    "    \n",
    "    outgoing_cpay_dict = {\"ACCOUNT\": [\"1021821845\"],\n",
    "                     \"AMOUNT\": [transaction_amount],\n",
    "                     \"NARRATION\": [f\"Outgoing CorporatePay {formatted_date}\"]}\n",
    "    \n",
    "    print(\"STEP 5: Negating the transaction amount because it is outgoing\")\n",
    "    outgoing_cpay_dict[\"AMOUNT\"] = [abs(transaction_amount) * -1]\n",
    "    \n",
    "    print(\"STEP 6: Creating the Final Narration DataFrame\")\n",
    "    outgoing_cpay_settlement_df = pd.DataFrame(outgoing_cpay_dict)\n",
    "    \n",
    "   # print(\"==END OF FUNCTION: OUTGOING CPAY DETAILS==\\n\")\n",
    "    return outgoing_cpay_settlement_df\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d3f6f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da1fec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd222489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01e69f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
